# Earth Engine Catalog Web Crawler Configuration
# Advanced configuration for the enhanced crawler

# Field definitions for data extraction
fields:
  - name: title
    selector: "h1, h2, h3, .title, .dataset-title"
    required: true
    type: text
    
  - name: description
    selector: ".description, .summary, .abstract, p"
    required: false
    type: text
    
  - name: provider
    selector: ".provider, .source, .organization"
    required: false
    type: text
    
  - name: spatial_coverage
    selector: ".spatial, .coverage, .region"
    required: false
    type: geospatial
    
  - name: temporal_coverage
    selector: ".temporal, .date, .time"
    required: false
    type: temporal
    
  - name: resolution
    selector: ".resolution, .scale"
    required: false
    type: numeric
    
  - name: bands
    selector: ".bands, .channels"
    required: false
    type: list
    
  - name: thumbnail
    selector: "img[src*='sample'], img[src*='preview']"
    required: false
    type: image

# Validation settings
validation:
  spatial:
    enabled: true
    validate_coordinates: true
    max_bbox_size: 360  # degrees
    
  temporal:
    enabled: true
    validate_dates: true
    min_year: 1970
    max_year: 2030
    
  data_quality:
    enabled: true
    min_description_length: 10
    max_title_length: 200
    
  consistency:
    enabled: true
    check_provider_consistency: true
    check_spatial_consistency: true

# ML/NLP settings
ml:
  classification:
    enabled: true
    model: "distilbert-base-uncased"
    confidence_threshold: 0.7
    max_length: 512
    
  ner:
    enabled: true
    model: "en_core_web_sm"
    extract_entities: ["ORG", "GPE", "DATE", "CARDINAL"]
    
  fallback:
    enabled: true
    rule_based_classification: true

# Geospatial settings
geospatial:
  enabled: true
  geocoder: "nominatim"
  user_agent: "earth_engine_crawler"
  timeout: 10
  max_retries: 3

# OCR settings
ocr:
  enabled: true
  extract_text_from_images: true
  confidence_threshold: 0.6
  languages: ["eng"]

# Dashboard settings
dashboard:
  enabled: true
  port: 8080
  auto_refresh: true
  refresh_interval: 5
  max_items: 1000

# Export settings
export:
  formats:
    - json
    - csv
    - excel
    - database
    
  database:
    enabled: true
    type: "sqlite"
    filename: "crawler_data.db"
    
  compression:
    enabled: true
    format: "gzip"

# Performance settings
performance:
  max_concurrent_requests: 5
  request_delay: 1.0
  timeout: 30
  max_retries: 3
  
  memory:
    max_cache_size: 1000
    cleanup_interval: 300
    
  monitoring:
    enabled: true
    log_performance: true
    track_memory: true

# Advanced features
advanced:
  plugins:
    - "custom_band_parser"
    - "thumbnail_ocr"
    
  ensemble_methods:
    enabled: true
    voting_threshold: 0.6
    
  data_enhancement:
    enabled: true
    enrich_with_external_data: false
    cross_reference_datasets: false

# Error handling
error_handling:
  max_errors: 100
  error_logging: true
  retry_failed_items: true
  graceful_degradation: true

# Logging
logging:
  level: "INFO"
  file: "crawler.log"
  max_file_size: "10MB"
  backup_count: 5
  format: "%(asctime)s - %(levelname)s - %(message)s" 